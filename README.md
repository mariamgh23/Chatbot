![Python](https://img.shields.io/badge/Python-3.9+-blue?style=flat-square)
![Streamlit](https://img.shields.io/badge/Streamlit-App-ff4b4b?style=flat-square)
![LangChain](https://img.shields.io/badge/LangChain-LLM-orange?style=flat-square)
![LangGraph](https://img.shields.io/badge/LangGraph-Workflow-purple?style=flat-square)
![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-black?style=flat-square)
![LLaMA3](https://img.shields.io/badge/LLaMA-3-green?style=flat-square)
![Status](https://img.shields.io/badge/Status-Active-success?style=flat-square)

# Customer Support 24/7 Chatbot ğŸ¤–ğŸ’¬

An AI-powered customer support chatbot built with **Streamlit**, **LangGraph**, and **LLaMA 3 (via Ollama)**.  
The chatbot automatically categorizes customer queries, analyzes sentiment, and generates appropriate responses in a clean, Instagram-style chat UI.

---

## âœ¨ Features

- ğŸ§  **LLM-powered reasoning** using LLaMA 3
- ğŸ—‚ **Automatic query categorization**
  - Technical
  - Billing
  - General
- ğŸ˜Š **Sentiment analysis**
  - Positive
  - Neutral
  - Negative
- ğŸš¨ **Automatic escalation** for negative sentiment
- ğŸ”€ **LangGraph workflow** for clean, modular logic
- ğŸ’¬ **Instagram-style chat UI** with Streamlit
- ğŸŒ™ **Dark theme interface**

---

## ğŸ— Architecture Overview

The application is split into two main parts:

### 1. AI Workflow (LangGraph)
The chatbot logic is implemented as a **state-based graph**:



Each step is handled by a dedicated node using LangChain + Ollama.

### 2. UI (Streamlit)
- Chat-style message bubbles
- User and bot messages visually separated
- Category and sentiment metadata displayed with each bot response
- Session-based chat history

---

## ğŸ§° Tech Stack

- **Python 3.9+**
- **Streamlit** â€“ UI
- **LangGraph** â€“ Workflow orchestration
- **LangChain** â€“ Prompt & LLM abstraction
- **Ollama** â€“ Local LLM runtime
- **LLaMA 3** â€“ Language model

---

## ğŸš€ Getting Started

### 1. Install Ollama
Make sure Ollama is installed and running locally.

```bash
ollama pull llama3
```
Verify:
```
ollama list
```
### 2. Clone the Repository
```
git clone https://github.com/your-username/customer-support-chatbot.git
cd customer-support-chatbot
```
### 3. Install Dependencies
```
pip install streamlit langchain langgraph langchain-ollama
```
### 4. Run the App
```
streamlit run app.py
```
Open your browser at:
```
http://localhost:8501
```
## ğŸ’¬ How It Works

**1. User submits a message in the chat UI**

**2. The message is sent through the LangGraph workflow**

**3. The system:**

* Classifies the category

* Analyzes sentiment

* Routes to the correct handler

**4. A response is generated by LLaMA 3**

**5. The response, category, and sentiment are displayed in the chat**

## ğŸ“ Project Structure
```
.
â”œâ”€â”€ app.py              # Main Streamlit application
â”œâ”€â”€ README.md           # Project documentation
```
## ğŸ” Notes

**This project runs entirely locally**

**No external API keys required**

**Ollama must be running in the background**

## ğŸ›  Possible Improvements

**Add user/bot avatars**

**Typing indicator animation**

**Conversation persistence (DB)**

**Multi-language support**

**Admin dashboard for escalations**

## ğŸ™Œ Acknowledgements

**Streamlit**

**LangChain**

**LangGraph**

**Ollama**

